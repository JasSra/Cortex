version: '3.8'
services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8080
      NEXT_PUBLIC_MSAL_CLIENT_ID: ${MSAL_CLIENT_ID}
      NEXT_PUBLIC_MSAL_AUTHORITY: ${MSAL_AUTHORITY}
      NEXT_PUBLIC_MSAL_KNOWN_AUTHORITIES: ${MSAL_KNOWN_AUTHORITIES:-jsraauth.b2clogin.com}
      NEXT_PUBLIC_TENANT_DOMAIN: ${TENANT_DOMAIN:-jsraauth.onmicrosoft.com}
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules

  backend:
    build: ./backend
    ports:
      - "8080:8080"
    environment:
      ASPNETCORE_URLS: "http://+:8080"
      OLLAMA_URL: "${OLLAMA_URL:-http://host.docker.internal:11434}"
      OLLAMA_MODEL: "${OLLAMA_MODEL:-llama3.2:3b}"
      OPENAI_API_KEY: "${OPENAI_API_KEY:-}"
      OPENAI_MODEL: "${OPENAI_MODEL:-gpt-4o-mini}"
      STT_URL: "${STT_URL:-http://host.docker.internal:8001}"
      TTS_URL: "${TTS_URL:-http://host.docker.internal:8002}"
      DATA_DIR: "/app/data"
      ALLOW_LOCAL_SCAN: "true"
      ConnectionStrings__DefaultConnection: "Data Source=/app/data/cortex.db"
      # Use the keys the code actually reads: prefer REDIS_CONNECTION; also support Redis:Connection
      REDIS_CONNECTION: "redis:6379"
      Redis__Connection: "redis:6379"
      CORS_ORIGINS: "${CORS_ORIGINS:-http://localhost:3000,http://127.0.0.1:3000}"
      # Azure AD B2C
      Authentication__Authority: ${MSAL_AUTHORITY}
      Authentication__ClientId: ${MSAL_CLIENT_ID}
    volumes:
      - ./data:/app/data
      - ./backend:/app/src
    depends_on:
      - redis
      - sqlite

  redis:
    image: redis/redis-stack:latest
    ports:
      - "6379:6379"
      - "8001:8001"
    volumes:
      - redis_data:/data

  sqlite:
    image: alpine:latest
    volumes:
      - ./data:/data
    command: ["tail", "-f", "/dev/null"]

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      OLLAMA_ORIGINS: "*"
    profiles: ["ai"]

  faster-whisper:
    image: linuxserver/faster-whisper:latest
    environment:
      WHISPER_MODEL: small
      WHISPER_LANGUAGE: auto
    volumes:
      - whisper_data:/app/data
    profiles: ["ai"]

  piper:
    image: rhasspy/piper:latest
    ports:
      - "8002:8002"
    command: ["--model", "en_US-lessac-medium", "--output_dir", "/data"]
    volumes:
      - piper_data:/data
    profiles: ["ai"]

volumes:
  redis_data:
  ollama_data:
  whisper_data:
  piper_data:
