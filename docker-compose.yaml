version: '3.8'
services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules

  backend:
    build: ./backend
    ports:
      - "8080:8080"
    environment:
      - ASPNETCORE_URLS=http://+:8080
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=llama3.2:3b
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=gpt-4o-mini
      - STT_URL=http://faster-whisper:8001
      - TTS_URL=http://piper:8002
      - DATA_DIR=/app/data
      - ALLOW_LOCAL_SCAN=true
      - ConnectionStrings__DefaultConnection=Data Source=/app/data/cortex.db
      - Redis__ConnectionString=redis:6379
    volumes:
      - ./data:/app/data
      - ./backend:/app/src
    depends_on:
      - redis
      - sqlite

  redis:
    image: redis/redis-stack:latest
    ports:
      - "6379:6379"
      - "8001:8001"
    volumes:
      - redis_data:/data

  sqlite:
    image: alpine:latest
    volumes:
      - ./data:/data
    command: ["tail", "-f", "/dev/null"]

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*

  faster-whisper:
    image: linuxserver/faster-whisper:latest
    ports:
      - "8001:8001"
    environment:
      - WHISPER_MODEL=small
      - WHISPER_LANGUAGE=auto
    volumes:
      - whisper_data:/app/data

  piper:
    image: rhasspy/piper:latest
    ports:
      - "8002:8002"
    command: ["--model", "en_US-lessac-medium", "--output_dir", "/data"]
    volumes:
      - piper_data:/data

volumes:
  redis_data:
  ollama_data:
  whisper_data:
  piper_data:
