# P0 – Backend MVP AI Prompt (Voice‑first Notes + RAG)

Use this as a single pass, end‑to‑end build plan. Follow steps in order. Keep outputs deterministic. Placeholders use {{ PLACEHOLDER }}.

## 0) Objectives

1. Primary: notes manage/search/interact via voice + manual.
2. AI Agent: voice layer to retrieve/classify/act on notes using DbContext + embeddings.
3. All notes (new/updated/imported) flow through RAG: local Redis vector store with OpenAI embeddings.
4. Frontend uses Microsoft Adaptive Cards generated by backend endpoints.

## 1) System Topology

1. Services: `api` (.NET 8), `worker` (jobs), `redis-stack`, `sqlite` (dev) / `postgres` (opt), `ollama|openai` (embeddings), `stt`+`tts` (adapters), `otel-collector`.
2. Protocols: REST for CRUD/search/RAG; WebSocket for voice sessions; SSE for streaming answers.
3. Envs: `dev` (SQLite), `prod` (PostgreSQL 15+). Metric units.

## 2) Data Model (EF Core)

1. **Note**(Id, UserId, Title, Content, Lang, Source, CreatedAt, UpdatedAt, IsDeleted, Version).
2. **NoteChunk**(Id, NoteId, Seq, Text, TokenCount, Sha256, CreatedAt).
3. **Embedding**(Id, ChunkId, Provider, Model, Dim, VectorRef, CreatedAt).
4. **Tag**(Id, Name); **NoteTag**(NoteId, TagId).
5. **Classification**(Id, NoteId, Label, Score, Model, CreatedAt).
6. **ActionLog**(Id, AgentSessionId, Tool, InputJson, ResultJson, Status, Latency\_ms, Ts).

## 3) Redis Vector Schema (RediSearch + JSON)

1. Keys: `chunk:{id}`, `embed:{chunkId}`. Streams: `stream:ingest`, `stream:embed` (Redis Streams with consumer groups).
2. JSON doc per chunk: `{ "noteId", "userId", "title", "labels", "createdAt", "text", "embedding" }`.
3. Index: HNSW VECTOR (dim derives from `Embedding:Dim`), M=16, EF=200; TEXT fields (title,text) BM25; TAG (userId,labels); NUMERIC (createdAt).

## 4) Pipelines

1. **Ingest** sources: manual, file (.txt/.md/.pdf/.docx), web clip, audio transcript.
2. Steps: normalise → lang-detect → sentence-aware chunk (\~800–1 000 tokens) → hash (sha256) → dedupe (file+chunk) → enqueue to `stream:embed` (Redis Streams).
3. **Embed**: batch 128–512 chunks; OpenAI `text-embedding-3-small` (specify) or local {{ PLACEHOLDER\_MODEL }}; store vector to Redis JSON; write EF rows.
4. **On Update**: diff content → re-chunk changed ranges only → re-embed affected chunks.
5. **On Delete**: soft-delete note; purge Redis keys via worker; log audit.

## 5) Retrieval (Hybrid)

1. API blends cosine(vector) and BM25: `score = α*cos + (1−α)*bm25`, α∈\[0.3..0.7]. Default α=0.6.
2. Filters: userId (required), dateFrom/dateTo (ISO 8601), labels, source.
3. Return: hits\[] with `noteId, chunkId, title, snippet, offsets, score`.

## 6) RAG Answering

1. `POST /rag/query { messages[], topK, alpha, filters }` → { answer, citations:\[{noteId,chunkId,offsets}], usage }.
2. Assemble context from topK chunks ≤ {{ PLACEHOLDER\_TOKENS }} tokens; cite sources.

## 7) API Surface (MVP)

1. **Notes CRUD**: `POST /notes` (Idempotency-Key), `GET /notes/{id}`, `PATCH /notes/{id}`, `DELETE /notes/{id}`.
2. **Search**: `POST /search { q, filters, k:topK, mode:"hybrid|semantic|bm25", alpha }` (default `mode=hybrid`, `alpha=0.6`).
3. **Ingest**: `POST /ingest/file` (multipart) → jobId; `POST /ingest/bulk` { items\[] }.
4. **RAG**: `POST /rag/query` (as above).
5. **Cards**: `POST /cards/list-notes { filter }`, `POST /cards/note/{id}` → Adaptive Card JSON v1.6.
6. **Agent Actions**: `POST /agent/act { tool, args }` for P0 tools (below).
7. **Admin**: `/health`, `/metrics`, `/admin/embed/reindex`, `/admin/embed/reembed` (aliases supported: `/admin/reindex`, `/admin/reembed`).

## 8) Agent Tooling (P0 set)

1. `CreateNote(title, content, tags[])` → noteId; enqueues embed.
2. `FindNotes(q, filters, topK)` → hits.
3. `DeleteNote(noteId)` → soft delete + purge job.
4. `TagNote(noteId, tags[])` → upsert tags.
5. `SummariseNote(noteId)` → short extractive summary (local LLM or API).

## 9) Voice Session (Backend Contracts)

1. WS messages: {type:"audio"|"partial"|"final"|"tool"|"card"|"error"}.
2. Flow: audio(16 kHz PCM) → STT partial (<300 ms) → intent+slots → tool call → response + optional Card.
3. Intents (rule-first): search/summarise/create/delete/tag.

## 10) Adaptive Cards Composer

1. Templates: `ListNotes`, `NoteDetail`, `ConfirmDelete`, `Disambiguate`.
2. Endpoint renders card JSON based on model input; no frontend logic leaks.

## 11) Observability

1. OTEL traces across API→Worker→Redis.
2. Metrics: ingest throughput (notes/s), queue depth, embed latency p50/p95, search p95, WS drops, STT WER %.
3. Logs: structured; correlation-id per request.

## 12) DevOps

1. Docker Compose services: `api`, `worker`, `redis-stack`, `db`, `otel-collector`, `prometheus`, `grafana`, `stt`, `tts`.
2. EF migrations gated in CI; seed with ≤1 000 sample notes when `SEED=true`.
3. Idempotent start-up: create FT index if missing; backfill embeddings if empty.

## 13) Acceptance Criteria (DoD)

1. Create→embed→search→rag works e2e with citations.
2. Hybrid search returns relevant hits with α tunable; p95 search < 300 ms @ 1 M chunks on mid-range server.
3. Voice intents trigger tools; Cards render for list/detail/delete.
4. Ingest ≤ 10 MB files; dedupe avoids duplicate chunks; re-embed on edits.

## 14) Config

1. `Embedding:Provider = "openai"|"local"`; `Embedding:Model = {{ PLACEHOLDER_MODEL }}`; `Embedding:Dim = {{ PLACEHOLDER_DIM }}`.
2. `Vector:Backend = "redis"|"qdrant"|"neo4j"` (default `redis`).
3. `Graph:Backend = "postgres"|"neo4j"` (default `postgres`).
4. `FeatureFlags:AdaptiveCards=true`.
5. Keys from {{ PLACEHOLDER\_SECRET\_MANAGER }}.

## 15) Non-Goals (P0)

1. Multi-tenant hard isolation, RBAC, share links.
2. Advanced policy engine/redaction.
3. Cross-encoder rerank (optional toggle only).

---

**Execute now**: scaffold DbContext/tables → Redis index → Ingest+Embed worker → `/search` hybrid → `/rag/query` → Agent tools → Cards endpoints → Voice WS routing.
